{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código com algumas alterações de: https://amandeepsaluja.com/extracting-job-information-from-linkedin-jobs-using-beautifulsoup-and-selenium/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta, datetime\n",
    "from IPython.core.display import clear_output\n",
    "from random import randint\n",
    "from requests import get\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from time import sleep\n",
    "from time import time\n",
    "start_time = time()\n",
    "\n",
    "from warnings import warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace variables here.\n",
    "# engenharia+mecanica NOT (\"seleção+engenharia\" OR \"divulga+vagas\")\n",
    "url = \"https://www.linkedin.com/jobs/search?keywords=engenharia%2Bmecanica%20NOT%20%28%22Sele%C3%A7%C3%A3o%2BEngenharia%22%20OR%20%22Divulga%2BVagas%22%29&location=Brasil&geoId=106057199&trk=public_jobs_jobs-search-bar_search-submit&redirect=false&position=1&pageNum=0\"\n",
    "no_of_jobs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will open up new window with the url provided above \n",
    "driver = webdriver.Chrome(r'C:\\Users\\marcellohro\\Downloads\\chromedriver.exe')\n",
    "driver.get(url)\n",
    "sleep(3)\n",
    "action = ActionChains(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show more jobs. Depends on number of jobs selected\n",
    "i = 2\n",
    "while i <= (no_of_jobs/25): \n",
    "    driver.find_element_by_xpath('/html/body/main/div/section/button').click()\n",
    "    i = i + 1\n",
    "    sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are scraping information about 625 jobs.\n"
     ]
    }
   ],
   "source": [
    "# parsing the visible webpage\n",
    "pageSource = driver.page_source\n",
    "lxml_soup = BeautifulSoup(pageSource, 'lxml')\n",
    "\n",
    "# searching for all job containers\n",
    "job_container = lxml_soup.find('ul', class_ = 'jobs-search__results-list')\n",
    "\n",
    "print('You are scraping information about {} jobs.'.format(len(job_container)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up list for job information\n",
    "job_id = []\n",
    "post_title = []\n",
    "company_name = []\n",
    "post_date = []\n",
    "job_location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop for job title, company, id, location and date posted\n",
    "for job in job_container:\n",
    "    \n",
    "    # job title\n",
    "    job_titles = job.find(\"span\", class_=\"screen-reader-text\").text\n",
    "    post_title.append(job_titles)\n",
    "    \n",
    "    # linkedin job id\n",
    "    job_ids = job.find('a', href=True)['href']\n",
    "    job_ids = re.findall(r'(?!-)([0-9]*)(?=\\?)',job_ids)[0]\n",
    "    job_id.append(job_ids)\n",
    "    \n",
    "    # company name\n",
    "    company_names = job.select_one('img')['alt']\n",
    "    company_name.append(company_names)\n",
    "    \n",
    "    # job location\n",
    "    job_locations = job.find(\"span\", class_=\"job-result-card__location\").text\n",
    "    job_location.append(job_locations)\n",
    "    \n",
    "    # posting date\n",
    "    post_dates = job.select_one('time')['datetime']\n",
    "    post_date.append(post_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up list for job information\n",
    "job_desc = []\n",
    "level = []\n",
    "emp_type = []\n",
    "functions = []\n",
    "industries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for loop for job description and criterias\n",
    "for x in range(1,601):\n",
    "    \n",
    "    # clicking on different job containers to view information about the job\n",
    "    job_xpath = '/html/body/main/div/section/ul/li[{}]/img'.format(x)\n",
    "    driver.find_element_by_xpath(job_xpath).click()\n",
    "    sleep(2)\n",
    "    \n",
    "    # clicking on show more\n",
    "    try:\n",
    "        job_xpath = '/html/body/main/section/div[2]/section[2]/div[2]/section/button[1]/icon'\n",
    "        driver.find_element_by_xpath(job_xpath).click()\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        job_xpath = '/html/body/main/section/div[2]/section[2]/div/section/button[1]/icon'\n",
    "        driver.find_element_by_xpath(job_xpath).click()\n",
    "    except Exception:\n",
    "        pass\n",
    "    sleep(0.5)\n",
    "        \n",
    "    # job description\n",
    "    jobdesc_xpath = '/html/body/main/section/div[2]/section[2]/div'\n",
    "    job_descs = driver.find_element_by_xpath(jobdesc_xpath).text\n",
    "    job_desc.append(job_descs)\n",
    "        \n",
    "    # job criteria container below the description\n",
    "    job_criteria_container = lxml_soup.find('ul', class_ = 'job-criteria__list')\n",
    "    all_job_criterias = job_criteria_container.find_all(\"span\", class_='job-criteria__text job-criteria__text--criteria')\n",
    "    \n",
    "    # Seniority level\n",
    "    seniority_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[1]'\n",
    "    seniority = driver.find_element_by_xpath(seniority_xpath).text.splitlines(0)[1]\n",
    "    level.append(seniority)\n",
    "    \n",
    "    # Employment type\n",
    "    type_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[2]'\n",
    "    employment_type = driver.find_element_by_xpath(type_xpath).text.splitlines(0)[1]\n",
    "    emp_type.append(employment_type)\n",
    "    \n",
    "    # Job function\n",
    "    function_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[3]'\n",
    "    job_function = driver.find_element_by_xpath(function_xpath).text.splitlines(0)[1]\n",
    "    functions.append(job_function)\n",
    "    \n",
    "    # Industries\n",
    "    try:\n",
    "        industry_xpath = '/html/body/main/section/div[2]/section[2]/ul/li[4]'\n",
    "        industry_type = driver.find_element_by_xpath(industry_xpath).text.splitlines(0)[1]\n",
    "        industries.append(industry_type)\n",
    "    except Exception:\n",
    "        industries.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if we have all information\n",
    "print(len(job_id))\n",
    "print(len(post_date))\n",
    "print(len(company_name))\n",
    "print(len(post_title))\n",
    "print(len(job_location))\n",
    "print(len(job_desc))\n",
    "print(len(level))\n",
    "print(len(emp_type))\n",
    "print(len(functions))\n",
    "print(len(industries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame({'Job ID': job_id[391:600],\n",
    "'Date': post_date[391:600],\n",
    "'Company Name': company_name[391:600],\n",
    "'Post': post_title[391:600],\n",
    "'Location': job_location[391:600],\n",
    "'Description': job_desc,\n",
    "'Level': level,\n",
    "'Type': emp_type,\n",
    "'Function': functions,\n",
    "'Industry': industries\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cleaning description column\n",
    "# job_data['Description'] = job_data['Description'].str.replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data.to_csv('LinkedIn Job Data.csv', index=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
